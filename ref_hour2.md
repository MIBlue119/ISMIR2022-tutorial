# References - 2nd hour



1. Pirker, Gregor, et al. "A pitch tracking corpus with evaluation on multipitch tracking scenario." *Twelfth annual conference of the international speech communication association*. 2011.
2. Molina, Emilio, et al. "Evaluation framework for automatic singing transcription." (2014).
3. Hono, Yukiya, et al. "Recent development of the DNN-based singing voice synthesis system—sinsy." *2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)*. IEEE, 2018.
4. Hono, Yukiya, et al. "Sinsy: A deep neural network-based singing voice synthesis system." *IEEE/ACM Transactions on Audio, Speech, and Language Processing* 29 (2021): 2803-2815.
5. Blaauw, Merlijn, and Jordi Bonada. "A neural parametric singing synthesizer." *arXiv preprint arXiv:1704.03809* (2017).
6. Bonada, Jordi, and Merlijn Blaauw. "Hybrid neural-parametric f0 model for singing synthesis." *ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2020.
7. Blaauw, Merlijn, and Jordi Bonada. "Sequence-to-sequence singing synthesis using the feed-forward transformer." ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020.
8. Zhang, Yongmao, et al. "Visinger: Variational inference with adversarial learning for end-to-end singing voice synthesis." *ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2022.
9. Wang, Chunhui, Chang Zeng, and Xing He. "Xiaoicesing 2: A High-Fidelity Singing Voice Synthesizer Based on Generative Adversarial Network." *arXiv preprint arXiv:2210.14666* (2022).
10. Liu, Jinglin, et al. "Diffsinger: Singing voice synthesis via shallow diffusion mechanism." *Proceedings of the AAAI Conference on Artificial Intelligence*. Vol. 36. No. 10. 2022.
11. Hua, Kanru. "Modeling singing F0 with neural network driven transition-sustain models." *arXiv preprint arXiv:1803.04030* (2018).
12. Yamamoto, Ryuichi, Eunwoo Song, and Jae-Min Kim. "Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram." *ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2020.
13. Kong, Jungil, Jaehyeon Kim, and Jaekyoung Bae. "Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis." *Advances in Neural Information Processing Systems* 33 (2020): 17022-17033.
14. Wang, Xin, Shinji Takaki, and Junichi Yamagishi. "Neural source-filter-based waveform model for statistical parametric speech synthesis." *ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2019.
15. Huang, Rongjie, et al. "Singgan: Generative adversarial network for high-fidelity singing voice generation." *Proceedings of the 30th ACM International Conference on Multimedia*. 2022.
16. Hono, Yukiya, et al. "PeriodNet: A non-autoregressive waveform generation model with a structure separating periodic and aperiodic components." *ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2021.
17. Yoneyama, Reo, Yi-Chiao Wu, and Tomoki Toda. "Unified Source-Filter GAN with Harmonic-plus-Noise Source Excitation Generation." *arXiv preprint arXiv:2205.06053* (2022).
18. Wang, Chunhui, Chang Zeng, and Xing He. "HiFi-WaveGAN: Generative Adversarial Network with Auxiliary Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation." *arXiv preprint arXiv:2210.12740* (2022).APA
19. Choi, Hyeong-Seok, et al. "NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis." *arXiv preprint arXiv:2211.09407* (2022).
20. Mohamed, Abdelrahman, et al. "Self-Supervised Speech Representation Learning: A Review." *arXiv preprint arXiv:2205.10643* (2022).