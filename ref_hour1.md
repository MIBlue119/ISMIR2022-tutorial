# References - 1st hour



## Slide 1-25

1. Dhariwal, P., & Nichol, A. (2021). Diffusion models beat gans on image synthesis. *Advances in Neural Information Processing Systems*, *34*, 8780-8794.
2. Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., & Sutskever, I. (2020). Jukebox: A generative model for music. *arXiv preprint arXiv:2005.00341*.
3. Oord, A. V. D., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. *arXiv preprint arXiv:1609.03499*.
4. Karras, T., Laine, S., & Aila, T. (2019). A style-based generator architecture for generative adversarial networks. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 4401-4410).
5. https://dreamtonics.com/en/synthesizerv/
6. https://github.com/CompVis/stable-diffusion
7. Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., & Aberman, K. (2022). Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. *arXiv preprint arXiv:2208.12242*.
8. https://runwayml.com/
9. Louie, R., Cohen, A., Huang, C. Z. A., Terry, M., & Cai, C. J. (2020). Cococo: AI-Steering Tools for Music Novices Co-Creating with Generative Models. In HAI-GEN+ user2agent@ IUI.
10. https://www.youtube.com/watch?v=vnRrGCB04WE
11. Llano, M. T., d'Inverno, M., Yee-King, M., McCormack, J., Ilsar, A., Pease, A., & Colton, S. (2022). Explainable computational creativity. *arXiv preprint arXiv:2205.05682*.



## Slide 25-46

TODO @ **Hyeong-Seok Choi**

Continue the above list and merge the subsequent list



## Slide 47-60

1. Sulun, S., Davies, M. E., & Viana, P. (2022). Symbolic music generation conditioned on continuous-valued emotions. *IEEE Access*, *10*, 44617-44626.
2. https://openai.com/blog/musenet/
3. Yu, Y., Srivastava, A., & Canales, S. (2021). Conditional lstm-gan for melody generation from lyrics. *ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)*, *17*(1), 1-20.
4. Harris, Z., Clarke, L. A., Gagliano, P., Camarena, D., Siddiqui, M., & Castro, P. S. (2021). Malakai: Music That Adapts to the Shape of Emotions. arXiv preprint arXiv:2112.02070.
5. Dai, S., Jin, Z., Gomes, C., & Dannenberg, R. B. (2021). Controllable deep melody generation via hierarchical music structure representation. arXiv preprint arXiv:2109.00663.
6. Young, H., Dumoulin, V., Castro, P. S., Engel, J., & Huang, C. Z. A. (2022). Compositional Steering of Music Transformers.
7. Ens, J., & Pasquier, P. (2020). Mmm: Exploring conditional multi-track music generation with the transformer. arXiv preprint arXiv:2008.06048.
8. Tan, H. H., & Herremans, D. (2020). Music fadernets: Controllable music generation based on high-level features via low-level feature modelling. *arXiv preprint arXiv:2007.15474*.
9. Roberts, A., Engel, J., Raffel, C., Hawthorne, C., & Eck, D. (2018, July). A hierarchical latent vector model for learning long-term structure in music. In International conference on machine learning (pp. 4364-4373). PMLR.
10. Louie, R., Cohen, A., Huang, C. Z. A., Terry, M., & Cai, C. J. (2020). Cococo: AI-Steering Tools for Music Novices Co-Creating with Generative Models. In HAI-GEN+ user2agent@ IUI.
11. Wang, Z., Wang, D., Zhang, Y., & Xia, G. (2020). Learning interpretable representation for controllable polyphonic music generation. *arXiv preprint arXiv:2008.07122*.
12. Streijl, R. C., Winkler, S., & Hands, D. S. (2016). Mean opinion score (MOS) revisited: methods and applications, limitations and alternatives. *Multimedia Systems*, *22* (2), 213-227.
13. https://en.wikipedia.org/wiki/Mean_opinion_score
14. Engel, J., Agrawal, K. K., Chen, S., Gulrajani, I., Donahue, C., & Roberts, A. (2019). Gansynth: Adversarial neural audio synthesis. *arXiv preprint arXiv:1902.08710*.
15. Nistal, J., Lattner, S., & Richard, G. (2020). Drumgan: Synthesis of drum sounds with timbral feature conditioning using generative adversarial networks. *arXiv preprint arXiv:2008.12073*.
16. Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved techniques for training gans. *Advances in neural information processing systems*, *29*.
17. Kilgour, K., Zuluaga, M., Roblek, D., & Sharifi, M. (2018). Fr\'echet Audio Distance: A Metric for Evaluating Music Enhancement Algorithms. *arXiv preprint arXiv:1812.08466*.
18. Bi≈Ñkowski, M., Sutherland, D. J., Arbel, M., & Gretton, A. (2018). Demystifying mmd gans. *arXiv preprint arXiv:1801.01401*.
19. Luce, R. D., & Edwards, W. (1958). The derivation of subjective scales from just noticeable differences. *Psychological review*, *65*(4), 222.
20. Wu, Y., Manilow, E., Deng, Y., Swavely, R., Kastner, K., Cooijmans, T., ... & Engel, J. (2021). MIDI-DDSP: Detailed control of musical performance via hierarchical modeling. *arXiv preprint arXiv:2112.09312*.
21. Nistal, J., Lattner, S., & Richard, G. (2020). Drumgan: Synthesis of drum sounds with timbral feature conditioning using generative adversarial networks. *arXiv preprint arXiv:2008.12073*.



## Slide 61-66

1. Norman, D. (2013). The design of everyday things: Revised and expanded edition. Basic books.
2. Preece, J., Rogers, Y., Sharp, H., Benyon, D., Holland, S., & Carey, T. (1994). *Human-computer interaction*. Addison-Wesley Longman Ltd..
3. Thelle, N. J., & Pasquier, P. (2021, April). Spire Muse: A Virtual Musical Partner for Creative Brainstorming. In NIME 2021. PubPub.
4. https://ismir2021.ismir.net/tutorials/#2-designing-generative-models-for-interactive-co-creation, https://www.youtube.com/watch?v=f0XO4A_-EeY
5. Molnar, C. (2020). *Interpretable machine learning*. Lulu. com.
6. Gou, J., Yu, B., Maybank, S. J., & Tao, D. (2021). Knowledge distillation: A survey. International Journal of Computer Vision, 129(6), 1789-1819.
7. https://magenta.tensorflow.org/ddsp-vst
8. Garcia, H. F., Aguilar, A., Manilow, E., Vedenko, D., & Pardo, B. (2021). Deep Learning Tools for Audacity: Helping Researchers Expand the Artist's Toolkit. arXiv preprint arXiv:2110.13323.
9. https://github.com/chrisdonahue/music-cocreation-tutorial, https://magenta.tensorflow.org/js-announce, https://tonejs.github.io/, https://webmidijs.org/, https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API

